{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff28023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SBM_attributed import *\n",
    "import torch\n",
    "import networkx as nx\n",
    "from divergences import * \n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import rand_score, calinski_harabasz_score, mutual_info_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e5b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate benchmark\n",
    "P = np.array([[0.8, 0.2, 0.3],[0.2, 0.7, 0.4],[0.3, 0.4, 0.6]])\n",
    "c = 3\n",
    "n = 100\n",
    "N = c*n\n",
    "delta = 10\n",
    "d = 2\n",
    "dim = c*d\n",
    "_,A,X = generate_benchmark(P,c,delta=delta,n=n,dim=d,sample_along_direction=True)\n",
    "A = torch.tensor(A)\n",
    "X = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd77beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize variables\n",
    "B = torch.eye(c,dtype=torch.float, requires_grad=True)\n",
    "W = torch.zeros((N,c),dtype=torch.float, requires_grad=True)\n",
    "indexes = torch.randint(low=0,high=c,size=(N,))\n",
    "with torch.no_grad():\n",
    "    for index,col in enumerate(indexes):\n",
    "        W[index].index_fill_(0, col, 1)\n",
    "mu = torch.tensor(np.random.normal(size=(c,dim)), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff1f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_net = get_phi(\"euclidean\",elementwise=True)[0]\n",
    "phi_data = get_phi(\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c578bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func(W,B,mu,norm):\n",
    "    net_divergence = torch.sum(phi_net(A,W@B@W.T), axis=1)\n",
    "    data_divergence = torch.sum(torch.multiply(W, pairwise_bregman(X, mu, phi_data)),axis=1)\n",
    "    K = torch.stack((net_divergence,data_divergence),axis=-1)\n",
    "    return torch.sum(torch.pow(torch.sum(torch.pow(K, norm), axis=1),1/norm))\n",
    "#     return torch.linalg.matrix_norm(K,ord=-np.inf,keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605cfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables are NAN'd, so terminating\n",
      "loss- tensor(inf, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "norm = -1\n",
    "lr=1e-2\n",
    "W_old = B_old = mu_old = classes_old = classes = None\n",
    "convergence_cnt = 0\n",
    "convergence_threshold = 5\n",
    "iter = 0\n",
    "loss = 0\n",
    "max_iter = 100000\n",
    "failed_to_converge = False\n",
    "while True:\n",
    "    iter += 1\n",
    "    loss = obj_func(W,B,mu,norm)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        # Save old variables\n",
    "        W_old = deepcopy(W)\n",
    "        B_old = deepcopy(B)\n",
    "        mu_old = deepcopy(mu)\n",
    "        # Gradient descent\n",
    "        W -= W.grad * lr \n",
    "        B -= B.grad * lr\n",
    "        mu -= mu.grad * lr\n",
    "        # Set the gradients to zero\n",
    "        W.grad.zero_()\n",
    "        B.grad.zero_()\n",
    "        mu.grad.zero_()\n",
    "        # Normalize variables\n",
    "        w_min = W.min(axis=1)[0][:, None].expand(-1,c)  \n",
    "        w_max = W.max(axis=1)[0][:, None].expand(-1,c)   \n",
    "        W -= w_min\n",
    "        W /= (w_max - w_min)\n",
    "        b_min = B.min(axis=1)[0][:, None].expand(-1,c)  \n",
    "        b_max = B.max(axis=1)[0][:, None].expand(-1,c)  \n",
    "        B -= b_min\n",
    "        B /= (b_max - b_min)\n",
    "        #anneal norm value\n",
    "        if iter % 2 == 0:\n",
    "            if norm > -1.0:\n",
    "                norm += -.2\n",
    "            elif norm > -120.0:\n",
    "                norm *= 1.06\n",
    "        # Check for nan values\n",
    "        if (torch.isnan(torch.norm(W)) or torch.isnan(torch.norm(B)) or torch.isnan(torch.norm(mu))):\n",
    "            print(\"variables are NAN'd, so terminating\")\n",
    "            mu = mu_old\n",
    "            B = B_old\n",
    "            W = W_old\n",
    "            print(\"loss-\",loss)\n",
    "            failed_to_converge = True\n",
    "            break\n",
    "        #update values\n",
    "        if classes is not None:\n",
    "            classes_old = classes\n",
    "        classes = torch.argmax(W, axis=1)\n",
    "        #Check convergence\n",
    "        if classes_old is not None and classes is not None and torch.equal(classes_old, classes):\n",
    "            convergence_cnt += 1\n",
    "        else:\n",
    "            convergence_cnt = 0\n",
    "        if convergence_cnt == convergence_threshold or iter>max_iter:\n",
    "            print(\"point assignments have converged\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5c86ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-126.00472097309353, 170)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm,iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515be2ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3311036789297659 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_labels = torch.argmax(W, axis=1).detach().numpy()\n",
    "true_labels = [0]*n + [1]*n + [2]*n\n",
    "print(rand_score(true_labels, pred_labels),mutual_info_score(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff3db0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9268, 1.0000, 0.0000],\n",
       "        [0.9420, 1.0000, 0.0000],\n",
       "        [0.9235, 1.0000, 0.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046c8565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 13.4918, -46.7543,  20.9008, -51.1834,  -6.0738,  17.0653],\n",
       "        [-63.7226, 112.3886,   2.5787,  -5.6345,  -0.8304,   8.2379],\n",
       "        [  5.4346, -19.4572,   7.9261, -19.6438,  -3.5641,   9.3086]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
