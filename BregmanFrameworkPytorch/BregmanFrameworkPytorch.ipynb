{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff28023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SBM_attributed import *\n",
    "import torch\n",
    "import networkx as nx\n",
    "from divergences import * \n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import rand_score, calinski_harabasz_score, mutual_info_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e5b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate benchmark\n",
    "P = np.array([[0.8, 0.2, 0.3],[0.2, 0.7, 0.4],[0.3, 0.4, 0.6]])\n",
    "c = 3\n",
    "n = 100\n",
    "N = c*n\n",
    "delta = 10\n",
    "d = 2\n",
    "dim = c*d\n",
    "_,A,X = generate_benchmark(P,c,delta=delta,n=n,dim=d,sample_along_direction=True)\n",
    "A = torch.tensor(A)\n",
    "X = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd77beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize variables\n",
    "B = torch.eye(c,dtype=torch.float, requires_grad=True)\n",
    "W = torch.zeros((N,c),dtype=torch.float, requires_grad=True)\n",
    "indexes = torch.randint(low=0,high=c,size=(N,))\n",
    "with torch.no_grad():\n",
    "    for index,col in enumerate(indexes):\n",
    "        W[index].index_fill_(0, col, 1)\n",
    "mu = torch.tensor(np.random.normal(size=(c,dim)), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff1f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_net = get_phi(\"euclidean\",elementwise=True)[0]\n",
    "phi_data = get_phi(\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c578bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func(W,B,mu,norm):\n",
    "    net_divergence = torch.sum(phi_net(A,W@B@W.T), axis=1)\n",
    "    data_divergence = torch.sum(torch.multiply(W, pairwise_bregman(X, mu, phi_data)),axis=1)\n",
    "    K = torch.stack((net_divergence,data_divergence),axis=-1)\n",
    "    return torch.sum(torch.pow(torch.sum(torch.pow(K, norm), axis=1),1/norm))\n",
    "    #return torch.linalg.matrix_norm(K,ord=norm,keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605cfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point assignments have converged\n"
     ]
    }
   ],
   "source": [
    "norm = -1\n",
    "lr=1e-2\n",
    "W_old = B_old = mu_old = classes_old = classes = None\n",
    "convergence_cnt = 0\n",
    "convergence_threshold = 5\n",
    "iter = 0\n",
    "loss = 0\n",
    "max_iter = 100000\n",
    "failed_to_converge = False\n",
    "while True:\n",
    "    iter += 1\n",
    "    loss = obj_func(W,B,mu,norm)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        # Save old variables\n",
    "        W_old = deepcopy(W)\n",
    "        B_old = deepcopy(B)\n",
    "        mu_old = deepcopy(mu)\n",
    "        # Gradient descent\n",
    "        W -= W.grad * lr \n",
    "        B -= B.grad * lr\n",
    "        mu -= mu.grad * lr\n",
    "        # Set the gradients to zero\n",
    "        W.grad.zero_()\n",
    "        B.grad.zero_()\n",
    "        mu.grad.zero_()\n",
    "        # Normalize variables\n",
    "        w_min = W.min()\n",
    "        w_max = W.max()\n",
    "        W -= w_min\n",
    "        W /= (w_max - w_min)\n",
    "        b_min = B.min()\n",
    "        b_max = B.max()\n",
    "        B -= b_min\n",
    "        B /= (b_max - b_min)\n",
    "        #anneal s value\n",
    "        if iter % 2 == 0:\n",
    "            if norm > -1.0:\n",
    "                norm += -.2\n",
    "            elif norm > -120.0:\n",
    "                norm *= 1.06\n",
    "        if (torch.isnan(torch.norm(W)) or torch.isnan(torch.norm(B)) or torch.isnan(torch.norm(mu))):\n",
    "            print(\"variables are NAN'd, so terminating\")\n",
    "            mu = mu_old\n",
    "            B = B_old\n",
    "            W = W_old\n",
    "            print(\"loss-\",loss)\n",
    "            failed_to_converge = True\n",
    "            break\n",
    "    \n",
    "        if classes is not None:\n",
    "            classes_old = classes\n",
    "        classes = torch.argmax(W, axis=1)\n",
    "        if classes_old is not None and classes is not None and torch.equal(classes_old, classes):\n",
    "            convergence_cnt += 1\n",
    "        else:\n",
    "            convergence_cnt = 0\n",
    "        if convergence_cnt == convergence_threshold or iter>max_iter:\n",
    "            print(\"point assignments have converged\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5c86ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.6894789590026928, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm,iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515be2ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3311036789297659 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_labels = torch.argmax(W, axis=1).detach().numpy()\n",
    "true_labels = [0]*n + [1]*n + [2]*n\n",
    "print(rand_score(true_labels, pred_labels),mutual_info_score(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62515a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9065, 0.2673, 0.5776],\n",
       "        [0.8539, 0.2917, 0.6073],\n",
       "        [0.9085, 0.2491, 0.5539],\n",
       "        [0.8947, 0.2388, 0.5272],\n",
       "        [0.8930, 0.3153, 0.6155],\n",
       "        [0.8584, 0.2073, 0.5929],\n",
       "        [0.8554, 0.2311, 0.5942],\n",
       "        [0.7955, 0.2204, 0.5432],\n",
       "        [0.8983, 0.2643, 0.5822],\n",
       "        [0.8959, 0.2593, 0.5801],\n",
       "        [0.8870, 0.2276, 0.5711],\n",
       "        [0.8706, 0.2319, 0.5832],\n",
       "        [0.9160, 0.3232, 0.6132],\n",
       "        [0.8982, 0.2385, 0.5625],\n",
       "        [0.8660, 0.2273, 0.5883],\n",
       "        [0.9067, 0.2977, 0.5892],\n",
       "        [0.9134, 0.3031, 0.5987],\n",
       "        [0.8986, 0.2620, 0.5893],\n",
       "        [0.8989, 0.2503, 0.5987],\n",
       "        [0.8025, 0.0115, 0.4672],\n",
       "        [0.8614, 0.2199, 0.5920],\n",
       "        [0.9089, 0.2726, 0.5705],\n",
       "        [0.8366, 0.1068, 0.5017],\n",
       "        [0.8436, 0.3409, 0.5937],\n",
       "        [0.8965, 0.2437, 0.5751],\n",
       "        [0.7833, 0.0000, 0.4868],\n",
       "        [0.9055, 0.2993, 0.6184],\n",
       "        [0.8352, 0.0993, 0.4488],\n",
       "        [0.9033, 0.4257, 0.6355],\n",
       "        [0.8259, 0.0835, 0.4542],\n",
       "        [0.8525, 0.1568, 0.5324],\n",
       "        [0.7950, 0.2274, 0.4654],\n",
       "        [0.8968, 0.3542, 0.6429],\n",
       "        [0.8357, 0.1155, 0.5138],\n",
       "        [0.8981, 0.2455, 0.5821],\n",
       "        [0.8232, 0.0765, 0.5022],\n",
       "        [0.8712, 0.2555, 0.6092],\n",
       "        [0.9133, 0.3167, 0.6280],\n",
       "        [0.8481, 0.2166, 0.5807],\n",
       "        [0.8883, 0.2557, 0.6040],\n",
       "        [0.8696, 0.1811, 0.5010],\n",
       "        [0.7862, 0.2101, 0.4047],\n",
       "        [0.8389, 0.1276, 0.5342],\n",
       "        [0.8755, 0.1882, 0.5206],\n",
       "        [0.8705, 0.2076, 0.5417],\n",
       "        [0.8487, 0.3092, 0.5942],\n",
       "        [0.9007, 0.3838, 0.6401],\n",
       "        [0.8924, 0.2293, 0.5458],\n",
       "        [0.8441, 0.2216, 0.5968],\n",
       "        [0.8952, 0.2922, 0.6157],\n",
       "        [0.8882, 0.2415, 0.5472],\n",
       "        [0.8927, 0.2646, 0.6086],\n",
       "        [0.8736, 0.1858, 0.5264],\n",
       "        [0.8308, 0.0956, 0.4884],\n",
       "        [0.8908, 0.2388, 0.5617],\n",
       "        [0.8645, 0.1750, 0.5466],\n",
       "        [0.8935, 0.3046, 0.6184],\n",
       "        [0.8417, 0.1585, 0.5630],\n",
       "        [0.8765, 0.2082, 0.5477],\n",
       "        [0.8666, 0.2015, 0.5489],\n",
       "        [0.8954, 0.3164, 0.6118],\n",
       "        [0.8237, 0.1039, 0.4974],\n",
       "        [0.8931, 0.2529, 0.5983],\n",
       "        [0.8461, 0.2087, 0.5856],\n",
       "        [0.8374, 0.0960, 0.4786],\n",
       "        [0.9103, 0.4742, 0.6261],\n",
       "        [0.8869, 0.2430, 0.5334],\n",
       "        [0.8881, 0.2107, 0.5952],\n",
       "        [0.9008, 0.2505, 0.5603],\n",
       "        [0.9061, 0.2735, 0.5926],\n",
       "        [0.8329, 0.1310, 0.5427],\n",
       "        [0.9175, 0.2961, 0.6055],\n",
       "        [0.8228, 0.2045, 0.5621],\n",
       "        [0.7994, 0.1708, 0.5082],\n",
       "        [0.8036, 0.1126, 0.5426],\n",
       "        [0.8619, 0.1767, 0.5530],\n",
       "        [0.9093, 0.2668, 0.5942],\n",
       "        [0.9112, 0.2765, 0.5602],\n",
       "        [0.8922, 0.3409, 0.6229],\n",
       "        [0.8453, 0.1314, 0.4703],\n",
       "        [0.8815, 0.2264, 0.5506],\n",
       "        [0.8846, 0.2511, 0.5942],\n",
       "        [0.8541, 0.2621, 0.6017],\n",
       "        [0.8552, 0.1714, 0.5231],\n",
       "        [0.8936, 0.2656, 0.6039],\n",
       "        [0.8298, 0.1686, 0.5586],\n",
       "        [0.8655, 0.2376, 0.5821],\n",
       "        [0.8963, 0.2852, 0.6166],\n",
       "        [0.8790, 0.2288, 0.5568],\n",
       "        [0.9220, 0.3172, 0.6145],\n",
       "        [0.8746, 0.1817, 0.5428],\n",
       "        [0.8875, 0.2847, 0.6042],\n",
       "        [0.8651, 0.1932, 0.5586],\n",
       "        [0.8964, 0.3377, 0.6210],\n",
       "        [0.8671, 0.1927, 0.5465],\n",
       "        [0.8709, 0.2838, 0.6067],\n",
       "        [0.9184, 0.3072, 0.6034],\n",
       "        [0.8699, 0.2078, 0.5513],\n",
       "        [0.8641, 0.2390, 0.6003],\n",
       "        [0.8419, 0.1187, 0.4802],\n",
       "        [0.8878, 0.3004, 0.6499],\n",
       "        [0.9854, 0.3516, 0.7058],\n",
       "        [0.9604, 0.3350, 0.6726],\n",
       "        [0.9464, 0.3262, 0.6578],\n",
       "        [0.9636, 0.3887, 0.6875],\n",
       "        [0.9430, 0.3200, 0.6695],\n",
       "        [0.9727, 0.3703, 0.7066],\n",
       "        [0.9357, 0.2806, 0.6120],\n",
       "        [0.9865, 0.3319, 0.7091],\n",
       "        [0.9756, 0.3654, 0.6983],\n",
       "        [0.9353, 0.2821, 0.6168],\n",
       "        [0.9550, 0.3221, 0.6753],\n",
       "        [0.9568, 0.3409, 0.6701],\n",
       "        [0.9486, 0.3259, 0.6522],\n",
       "        [0.9272, 0.2662, 0.5999],\n",
       "        [0.9570, 0.3377, 0.6743],\n",
       "        [0.9221, 0.2668, 0.5793],\n",
       "        [0.9008, 0.2196, 0.5425],\n",
       "        [0.9852, 0.3568, 0.7078],\n",
       "        [0.9505, 0.3212, 0.6636],\n",
       "        [0.9002, 0.2158, 0.5564],\n",
       "        [0.9460, 0.2976, 0.6449],\n",
       "        [0.9762, 0.4107, 0.7046],\n",
       "        [0.9710, 0.3719, 0.6921],\n",
       "        [0.9891, 0.3496, 0.7161],\n",
       "        [0.9337, 0.3232, 0.6541],\n",
       "        [0.9779, 0.3487, 0.6968],\n",
       "        [0.9564, 0.3027, 0.6578],\n",
       "        [0.9316, 0.2676, 0.6175],\n",
       "        [0.9530, 0.3339, 0.6858],\n",
       "        [0.9335, 0.3009, 0.6590],\n",
       "        [0.9578, 0.3496, 0.6885],\n",
       "        [0.9483, 0.3267, 0.6470],\n",
       "        [0.9079, 0.1968, 0.6040],\n",
       "        [1.0000, 0.4184, 0.7361],\n",
       "        [0.9518, 0.2956, 0.6501],\n",
       "        [0.9371, 0.2987, 0.6489],\n",
       "        [0.9477, 0.3043, 0.6521],\n",
       "        [0.9585, 0.3809, 0.6891],\n",
       "        [0.9730, 0.3127, 0.6844],\n",
       "        [0.9043, 0.2179, 0.5758],\n",
       "        [0.9432, 0.3011, 0.6195],\n",
       "        [0.9243, 0.2741, 0.6331],\n",
       "        [0.9580, 0.3302, 0.6717],\n",
       "        [0.9210, 0.2525, 0.5943],\n",
       "        [0.9013, 0.1879, 0.5636],\n",
       "        [0.9570, 0.3541, 0.6737],\n",
       "        [0.9941, 0.3508, 0.7216],\n",
       "        [0.8799, 0.1407, 0.5546],\n",
       "        [0.9726, 0.3251, 0.6813],\n",
       "        [0.9550, 0.3069, 0.6466],\n",
       "        [0.9598, 0.3137, 0.6579],\n",
       "        [0.9380, 0.2934, 0.6135],\n",
       "        [0.9364, 0.2858, 0.6473],\n",
       "        [0.9042, 0.2286, 0.5872],\n",
       "        [0.8993, 0.2105, 0.5460],\n",
       "        [0.9515, 0.3062, 0.6549],\n",
       "        [0.9563, 0.3119, 0.6480],\n",
       "        [0.9392, 0.2903, 0.6258],\n",
       "        [0.9596, 0.3134, 0.6586],\n",
       "        [0.9770, 0.3744, 0.7003],\n",
       "        [0.9628, 0.3523, 0.6888],\n",
       "        [0.9504, 0.2960, 0.6491],\n",
       "        [0.8978, 0.2463, 0.5167],\n",
       "        [0.9750, 0.3966, 0.7027],\n",
       "        [0.9479, 0.2912, 0.6461],\n",
       "        [0.9159, 0.2599, 0.6365],\n",
       "        [0.8782, 0.1429, 0.5444],\n",
       "        [0.9837, 0.3494, 0.7027],\n",
       "        [0.9801, 0.3674, 0.7048],\n",
       "        [0.9759, 0.3583, 0.6943],\n",
       "        [0.9709, 0.3355, 0.6807],\n",
       "        [0.9573, 0.3222, 0.6621],\n",
       "        [0.9192, 0.2474, 0.6233],\n",
       "        [0.9305, 0.2908, 0.5971],\n",
       "        [0.9722, 0.3279, 0.6836],\n",
       "        [0.9830, 0.3594, 0.7078],\n",
       "        [0.9380, 0.2965, 0.6638],\n",
       "        [0.9603, 0.3466, 0.6820],\n",
       "        [0.9268, 0.2710, 0.5960],\n",
       "        [0.9143, 0.2770, 0.6395],\n",
       "        [0.8795, 0.1688, 0.5090],\n",
       "        [0.9575, 0.2921, 0.6529],\n",
       "        [0.9131, 0.3160, 0.6437],\n",
       "        [0.9743, 0.3158, 0.6863],\n",
       "        [0.9219, 0.2601, 0.5963],\n",
       "        [0.9748, 0.3796, 0.7148],\n",
       "        [0.9731, 0.3946, 0.7011],\n",
       "        [0.9574, 0.3067, 0.6493],\n",
       "        [0.8980, 0.1979, 0.5682],\n",
       "        [0.9717, 0.3545, 0.6887],\n",
       "        [0.9022, 0.3216, 0.6578],\n",
       "        [0.8976, 0.1880, 0.5771],\n",
       "        [0.9615, 0.3132, 0.6682],\n",
       "        [0.9431, 0.2885, 0.6303],\n",
       "        [0.9818, 0.3940, 0.7062],\n",
       "        [0.9322, 0.3259, 0.6699],\n",
       "        [0.9726, 0.3395, 0.6860],\n",
       "        [0.9316, 0.2647, 0.6090],\n",
       "        [0.9774, 0.3606, 0.6986],\n",
       "        [0.8943, 0.1330, 0.5524],\n",
       "        [0.9353, 0.2340, 0.6227],\n",
       "        [0.9385, 0.2376, 0.6459],\n",
       "        [0.9567, 0.3083, 0.6703],\n",
       "        [0.9351, 0.2327, 0.6380],\n",
       "        [0.9491, 0.2614, 0.6329],\n",
       "        [0.9454, 0.2750, 0.6497],\n",
       "        [0.9280, 0.2176, 0.6344],\n",
       "        [0.9294, 0.2683, 0.6706],\n",
       "        [0.9493, 0.2581, 0.6434],\n",
       "        [0.9093, 0.1516, 0.6220],\n",
       "        [0.9479, 0.2469, 0.6274],\n",
       "        [0.9068, 0.1526, 0.5905],\n",
       "        [0.9522, 0.2591, 0.6529],\n",
       "        [0.9901, 0.3115, 0.7078],\n",
       "        [0.9309, 0.2039, 0.6186],\n",
       "        [0.9599, 0.3177, 0.7030],\n",
       "        [0.9544, 0.3058, 0.6755],\n",
       "        [0.9440, 0.2857, 0.6808],\n",
       "        [0.9711, 0.3009, 0.6816],\n",
       "        [0.9561, 0.2916, 0.6763],\n",
       "        [0.9730, 0.3095, 0.6884],\n",
       "        [0.9293, 0.2298, 0.6220],\n",
       "        [0.9313, 0.2192, 0.6194],\n",
       "        [0.9554, 0.2795, 0.6605],\n",
       "        [0.9403, 0.2551, 0.6234],\n",
       "        [0.9600, 0.3603, 0.6987],\n",
       "        [0.9752, 0.2879, 0.6831],\n",
       "        [0.9524, 0.2596, 0.6595],\n",
       "        [0.9372, 0.2967, 0.6812],\n",
       "        [0.9524, 0.2645, 0.6372],\n",
       "        [0.9518, 0.2672, 0.6524],\n",
       "        [0.9365, 0.2668, 0.6760],\n",
       "        [0.9514, 0.2519, 0.6431],\n",
       "        [0.8692, 0.0474, 0.5324],\n",
       "        [0.9315, 0.2295, 0.5995],\n",
       "        [0.9369, 0.2428, 0.6137],\n",
       "        [0.9150, 0.1971, 0.6509],\n",
       "        [0.9726, 0.2934, 0.6803],\n",
       "        [0.9098, 0.1672, 0.6260],\n",
       "        [0.9208, 0.2047, 0.6139],\n",
       "        [0.9457, 0.2981, 0.6662],\n",
       "        [0.9358, 0.2339, 0.6334],\n",
       "        [0.9558, 0.2816, 0.6697],\n",
       "        [0.9773, 0.3364, 0.6983],\n",
       "        [0.9612, 0.2904, 0.6825],\n",
       "        [0.9398, 0.2645, 0.6677],\n",
       "        [0.9418, 0.2639, 0.6456],\n",
       "        [0.9432, 0.2556, 0.6483],\n",
       "        [0.9402, 0.2395, 0.6299],\n",
       "        [0.9505, 0.2715, 0.6697],\n",
       "        [0.9056, 0.1804, 0.6442],\n",
       "        [0.9786, 0.3658, 0.7128],\n",
       "        [0.9247, 0.2166, 0.6326],\n",
       "        [0.9384, 0.2505, 0.6024],\n",
       "        [0.9060, 0.1546, 0.5875],\n",
       "        [0.9263, 0.2248, 0.6694],\n",
       "        [0.9109, 0.1771, 0.6447],\n",
       "        [0.9033, 0.1651, 0.6241],\n",
       "        [0.9265, 0.1988, 0.6230],\n",
       "        [0.9746, 0.3273, 0.6982],\n",
       "        [0.9754, 0.3236, 0.6928],\n",
       "        [0.9417, 0.2634, 0.6753],\n",
       "        [0.9154, 0.2230, 0.6427],\n",
       "        [0.8986, 0.1471, 0.6363],\n",
       "        [0.9103, 0.3039, 0.6623],\n",
       "        [0.8863, 0.1186, 0.5501],\n",
       "        [0.9073, 0.1754, 0.5623],\n",
       "        [0.9687, 0.3703, 0.6980],\n",
       "        [0.9593, 0.2995, 0.6755],\n",
       "        [0.9325, 0.2197, 0.6438],\n",
       "        [0.9567, 0.2736, 0.6598],\n",
       "        [0.9359, 0.2438, 0.6328],\n",
       "        [0.9240, 0.2190, 0.5991],\n",
       "        [0.9601, 0.3075, 0.6901],\n",
       "        [0.9496, 0.2634, 0.6497],\n",
       "        [0.8871, 0.1170, 0.6034],\n",
       "        [0.9557, 0.2727, 0.6450],\n",
       "        [0.9158, 0.1816, 0.6137],\n",
       "        [0.8843, 0.0873, 0.6154],\n",
       "        [0.9701, 0.3034, 0.6834],\n",
       "        [0.9531, 0.2673, 0.6530],\n",
       "        [0.9814, 0.2972, 0.6954],\n",
       "        [0.8884, 0.1109, 0.6034],\n",
       "        [0.8844, 0.0961, 0.5255],\n",
       "        [0.9245, 0.2335, 0.6269],\n",
       "        [0.9477, 0.3498, 0.7009],\n",
       "        [0.9644, 0.2852, 0.6646],\n",
       "        [0.9376, 0.2685, 0.6607],\n",
       "        [0.9380, 0.2431, 0.6228],\n",
       "        [0.9456, 0.2692, 0.6234],\n",
       "        [0.9501, 0.3106, 0.6816],\n",
       "        [0.9259, 0.2224, 0.6364],\n",
       "        [0.9511, 0.2600, 0.6452],\n",
       "        [0.9775, 0.3033, 0.6912],\n",
       "        [0.9073, 0.1759, 0.5868],\n",
       "        [0.8949, 0.1311, 0.5877],\n",
       "        [0.9804, 0.4083, 0.7152],\n",
       "        [0.9487, 0.2548, 0.6393],\n",
       "        [0.8562, 0.1756, 0.6158]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "010288c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.2, 0.3],\n",
       "       [0.2, 0.7, 0.4],\n",
       "       [0.3, 0.4, 0.6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ff3db0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.4321, 0.6950],\n",
       "        [0.4969, 0.7382, 0.8861],\n",
       "        [0.7943, 0.9225, 1.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "046c8565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3618, -2.1854, -3.0756, -5.7328, -5.6794, -2.6108],\n",
       "        [ 1.4500,  4.7212,  6.3004,  3.9607,  5.2399,  1.6690],\n",
       "        [-1.3957, -2.1459, -3.6560, -5.7952, -5.8293, -2.5820]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
